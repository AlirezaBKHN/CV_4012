{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNKYy5P_DEV-"
      },
      "source": [
        "## Modifying the picture with opencv and numpy libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yexCZ1RCByIY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7.weights "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov7.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Z72Jw09-zmZ"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNetFromDarknet('yolov7.cfg', 'yolov7.weights')\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_RCASdxi--fw"
      },
      "outputs": [],
      "source": [
        "yolo_model = cv2.dnn_DetectionModel(net)\n",
        "yolo_model.setInputParams(size=(1280, 1280), scale=1 / 255, swapRB=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xThGxCMDDUFO"
      },
      "source": [
        "**Just run the above cells without any changes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CBTcXsRpKjRM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image shape: (721, 1281, 3)\n",
            "image data type: uint8\n",
            "average of values in whole image: 139.98719468688319\n",
            "maximum of all channels: \n",
            "[[147 136 175 ... 191 191 191]\n",
            " [149 149 172 ... 191 190 191]\n",
            " [156 177 171 ... 190 190 190]\n",
            " ...\n",
            " [122 122 123 ... 142 141 142]\n",
            " [123 124 124 ... 142 142 142]\n",
            " [123 123 123 ... 141 140 140]]\n",
            "minimum of all channels: \n",
            "[[126 113 152 ... 154 154 154]\n",
            " [128 128 149 ... 154 153 154]\n",
            " [135 156 148 ... 153 153 153]\n",
            " ...\n",
            " [121 121 122 ... 139 138 139]\n",
            " [122 123 123 ... 139 139 139]\n",
            " [122 122 122 ... 138 137 137]]\n",
            "Maximum value in Red Channel: 255\n",
            "Maximum value in Green Channel: 255\n",
            "Maximum value in Blue Channel: 255\n",
            "Minimum value in Red Channel: 0\n",
            "Minimum value in Green Channel: 10\n",
            "Minimum value in Blue Channel: 0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Please read the provided image in RGB with opencv lib and print the matrices\n",
        "\n",
        "see bellow links:\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.maximum.html\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.minimum.html\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.mean.html\n",
        "\"\"\"\n",
        "\n",
        "image = cv2.imread('Q5.png')\n",
        "print(f'image shape: {image.shape}')\n",
        "print(f'image data type: {image.dtype}')\n",
        "print(f'average of values in whole image: {np.mean(image)}')\n",
        "print(f'maximum of all channels: \\n{np.maximum(image[:,:,0],image[:,:,1],image[:,:,2])}')\n",
        "print(f'minimum of all channels: \\n{np.minimum(image[:,:,0],image[:,:,1],image[:,:,2])}')\n",
        "\n",
        "print(f'Maximum value in Red Channel: {image[:,:,2].max()}\\nMaximum value in Green Channel: {image[:,:,1].max()}\\nMaximum value in Blue Channel: {image[:,:,0].max()}')\n",
        "print(f'Minimum value in Red Channel: {image[:,:,2].min()}\\nMinimum value in Green Channel: {image[:,:,1].min()}\\nMinimum value in Blue Channel: {image[:,:,0].min()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N3xB0Rh2FRZ_"
      },
      "outputs": [],
      "source": [
        "\n",
        "#### Just run this cell \n",
        "\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.2\n",
        "NMS_THRESHOLD = 0.4 \n",
        "\n",
        "classes, scores, boxes = yolo_model.detect(image, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
        "\n",
        "detections = [(box, score) for classid, score, box in zip(classes, scores, boxes)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot4ivZb6H7r7"
      },
      "source": [
        "the result of the detection is classes of each object, \n",
        "confidence of predicting the class of that object and parameters of the bounding box\n",
        "\n",
        "for every bounding box, we have bellow information:\n",
        "\n",
        "x_min: the x coordinate of the left up corner of the bounding box\n",
        "\n",
        "y_min: the y coordinate of the left up corner of the bounding box\n",
        "\n",
        "w: the width of the bounding box\n",
        "\n",
        "h: the height of the bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GjB_FADQH7bF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_min: 912, y_min: 634, w: 58, h: 86\n",
            "x_min: 783, y_min: 384, w: 40, h: 82\n",
            "x_min: 712, y_min: 390, w: 34, h: 88\n",
            "x_min: 744, y_min: 388, w: 31, h: 78\n",
            "x_min: 1000, y_min: 105, w: 16, h: 33\n",
            "x_min: 141, y_min: 317, w: 31, h: 76\n",
            "x_min: 786, y_min: 487, w: 70, h: 89\n",
            "x_min: 1044, y_min: 0, w: 8, h: 9\n",
            "x_min: 612, y_min: 140, w: 17, h: 36\n",
            "x_min: 165, y_min: 348, w: 23, h: 48\n",
            "x_min: 1004, y_min: 35, w: 8, h: 13\n",
            "x_min: 560, y_min: 168, w: 14, h: 23\n",
            "x_min: 633, y_min: 139, w: 11, h: 37\n",
            "x_min: 981, y_min: 30, w: 10, h: 17\n",
            "x_min: 853, y_min: 378, w: 32, h: 55\n",
            "x_min: 834, y_min: 496, w: 22, h: 48\n",
            "x_min: 899, y_min: 23, w: 11, h: 14\n",
            "x_min: 623, y_min: 32, w: 13, h: 17\n",
            "x_min: 1187, y_min: 60, w: 11, h: 12\n",
            "x_min: 1128, y_min: 475, w: 33, h: 51\n",
            "x_min: 869, y_min: 673, w: 134, h: 47\n",
            "x_min: 603, y_min: 40, w: 24, h: 13\n",
            "x_min: 867, y_min: 414, w: 16, h: 43\n",
            "x_min: 881, y_min: 383, w: 25, h: 55\n",
            "x_min: 579, y_min: 56, w: 8, h: 12\n",
            "x_min: 554, y_min: 60, w: 14, h: 12\n",
            "x_min: 562, y_min: 177, w: 18, h: 15\n",
            "x_min: 744, y_min: 313, w: 114, h: 91\n",
            "x_min: 850, y_min: 250, w: 82, h: 72\n",
            "x_min: 421, y_min: 109, w: 101, h: 34\n",
            "x_min: 891, y_min: 191, w: 67, h: 57\n",
            "x_min: 647, y_min: 268, w: 110, h: 94\n",
            "x_min: 1131, y_min: 58, w: 32, h: 17\n",
            "x_min: 1134, y_min: 47, w: 30, h: 12\n",
            "x_min: 1105, y_min: 18, w: 22, h: 19\n",
            "x_min: 616, y_min: 16, w: 40, h: 21\n",
            "x_min: 634, y_min: 53, w: 45, h: 24\n",
            "x_min: 445, y_min: 83, w: 136, h: 34\n",
            "x_min: 445, y_min: 94, w: 71, h: 18\n",
            "x_min: 1119, y_min: 0, w: 20, h: 8\n",
            "x_min: 1078, y_min: 487, w: 93, h: 50\n",
            "x_min: 1152, y_min: 13, w: 19, h: 22\n",
            "x_min: 512, y_min: 41, w: 36, h: 17\n"
          ]
        }
      ],
      "source": [
        "### please print the details of the detections\n",
        "for det in detections:\n",
        "    print(f'x_min: {det[0][0]}, y_min: {det[0][1]}, w: {det[0][2]}, h: {det[0][3]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OplX-80cLma3"
      },
      "outputs": [],
      "source": [
        "def visualize(frame, detections):\n",
        "  \"\"\"\n",
        "  Draw all bounding boxes on the main original image and show the result\n",
        "  Then save result with result.png name\n",
        "\n",
        "  see the bellow links:\n",
        "  https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\n",
        "  https://www.geeksforgeeks.org/python-opencv-cv2-imwrite-method/\n",
        "  \"\"\"\n",
        "\n",
        "  ########################################\n",
        "  ########### YOUR CODES GO HERE #########\n",
        "  \n",
        "  generated_img = frame\n",
        "  for det in detections:\n",
        "    cv2.rectangle(generated_img,pt1=(det[0][0],det[0][1]),pt2=(det[0][0]+det[0][2],det[0][1]+det[0][3])\n",
        "                  , color=(0,255,0), thickness=6)\n",
        "  cv2.imwrite('result.png',generated_img)\n",
        "  ########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bPc3unKsLwaj"
      },
      "outputs": [],
      "source": [
        "visualize(image, detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1903.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "result.png\n",
            "yes\n"
          ]
        }
      ],
      "source": [
        "# Check if file has been saved or not\n",
        "!(ls result.png && echo yes) || echo no"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
